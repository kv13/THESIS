{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import os\n",
    "import re\n",
    "import bs4\n",
    "import csv\n",
    "import time\n",
    "import requests\n",
    "import json, codecs\n",
    "from pprint import pprint\n",
    "from github import Github\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_json(page_objects):\n",
    "    with open('data.json','a') as f:\n",
    "        json.dump(page_objects,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define functions \n",
    "def find_tags(tags,each_issue):\n",
    "    \n",
    "    for counter,temp in enumerate(each.find_all('a')):\n",
    "        tag = str(temp.string)\n",
    "        tags.append(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_desc(each,base_url,description,stack_trace):\n",
    "    \n",
    "    next_url     = base_url+each.find('a')['href']\n",
    "    response     = requests.get(next_url)\n",
    "    html_content = response.content\n",
    "    dom          = BeautifulSoup(html_content,'html.parser')\n",
    "    temp         = dom.find('div',class_ = 'edit-comment-hide')\n",
    "    temp_2       = temp.find('td')\n",
    "    \n",
    "    #find description and the stack trace\n",
    "    calculate_desc(temp_2,description,stack_trace)\n",
    "    \n",
    "    #find the person who closed the issue\n",
    "    temp_3       = dom.find_all('div',class_='TimelineItem-body') \n",
    "    for i in temp_3:\n",
    "        if i.text.find('closed this')!=-1:\n",
    "            if i.find('a',class_='author Link--primary text-bold') is None:\n",
    "                continue\n",
    "            who_closed_it = i.find('a',class_='author Link--primary text-bold').text\n",
    "    \n",
    "    return who_closed_it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_desc(html_text,description,stack_trace):\n",
    "    \n",
    "    html_content = html_text.contents\n",
    "    length = len(html_content)\n",
    "    \n",
    "    if length == 1:\n",
    "        #some lines are empty. No need to write them\n",
    "        if html_content[0]!= []:\n",
    "            str_temp = str(html_content[0])\n",
    "            if str_temp.find('java.')!=-1 or str_temp.find('AndroidRuntime:')!=-1:\n",
    "                stack_trace.append(str(html_content[0]))\n",
    "            else:\n",
    "                description.append(str(html_content[0]))\n",
    "    else:\n",
    "        for i in range(length):\n",
    "\n",
    "            if type(html_content[i]) is bs4.element.NavigableString:\n",
    "                #avoid writting empty lines and html tags <br>\n",
    "                if len(html_content[i])>4:\n",
    "                    description.append(html_content[i])\n",
    "            elif type(html_content[i] is bs4.element.Tag):\n",
    "                #call recursively the function till length is 1\n",
    "                calculate_desc(html_content[i],description,stack_trace)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#search all closed issues\n",
    "\n",
    "#define some variables\n",
    "total_issues  = 0\n",
    "total_traces = 0\n",
    "\n",
    "#initialize important url's\n",
    "base_url = \"https://github.com/\"\n",
    "#query_url = f\"https://github.com/cgeo/cgeo/issues?page=1&q=is%3Aissue+is%3Aclosed\"\n",
    "query_url = f\"https://github.com/cgeo/cgeo/issues?page=6&q=is%3Aissue+is%3Aclosed\"\n",
    "\n",
    "#authorization in order to make more requests.\n",
    "token = os.getenv(\"GITHUB_TOKEN\")\n",
    "headers = {'Authorization': f'token {token}'}\n",
    "\n",
    "response = requests.get(query_url, headers = headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop through all pages\n",
    "\n",
    "while True:\n",
    "    response_code = response.status_code\n",
    "    if response_code != 200:\n",
    "        raise Exception(\"Error Occured\")\n",
    "    else:\n",
    "        html_content = response.content\n",
    "        dom = BeautifulSoup(html_content,'html.parser')\n",
    "        \n",
    "        #find all issues in every page\n",
    "        all = dom.findAll('div', class_='flex-auto min-width-0 p-2 pr-3 pr-md-2')\n",
    "        \n",
    "        page_objects = []\n",
    "        \n",
    "        #real scraping begins\n",
    "        for each in all:\n",
    "            \n",
    "            #find tags and who open the issue\n",
    "            tags=[]\n",
    "            find_tags(tags,each)\n",
    "            \n",
    "            \n",
    "            #find description, stack trace and who closed\n",
    "            description   = []\n",
    "            stack_trace   = []\n",
    "            who_closed_it = find_desc(each,base_url,description,stack_trace)\n",
    "            \n",
    "            total_issues = total_issues+1\n",
    "            if stack_trace !=[]:\n",
    "                total_traces = total_traces +1\n",
    "            \n",
    "            #write dictionary\n",
    "            if len(tags)>=1:    \n",
    "                issue_object = {'name':tags[0],'tags':tags[1:len(tags)-1],'opened_by':tags[len(tags)-1],\n",
    "                               'description':description,'stack_trace':stack_trace,'closed_by':who_closed_it}\n",
    "           \n",
    "            page_objects.append(issue_object)\n",
    "            \n",
    "        #write issues to json file\n",
    "        write_json(page_objects)\n",
    "        \n",
    "        #visit the next page if exists\n",
    "        end = dom.findAll('a',class_='next_page')\n",
    "        \n",
    "        if end ==[]:\n",
    "            break\n",
    "        next_url = base_url+end[1]['href']\n",
    "        response = requests.get(next_url)\n",
    "        # Sleep for 60 seconds\n",
    "        time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more generic how to find the stack trace\n",
    "# export in json\n",
    "# for every issue take also and the description\n",
    "# take who closed the issue.===>This person possibly solve it to\n",
    "########################################################################\n",
    "# find total number of stack traces, find the total files\n",
    "# ftiaksw parametrika diavazontas tis teleies.\n",
    "# find for each file in how many stack traces appears.\n",
    "#-----------------------------------------------------------------------\n",
    "# predict tags in open issues\n",
    "# from stack traces take the file which the bug occured\n",
    "# make knowledge graph.?!later."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py38] *",
   "language": "python",
   "name": "conda-env-py38-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
